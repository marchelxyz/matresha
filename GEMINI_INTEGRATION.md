# Интеграция Gemini - Улучшения

## Что было сделано

### 1. Поддержка ChatSession
- Интеграция теперь использует `ChatSession` для правильной работы с историей разговора
- История сообщений корректно передается в Gemini API
- Поддержка контекста между сообщениями в диалоге

### 2. Обновление моделей
- Используется новая модель `gemini-1.5-flash` (быстрая и эффективная)
- Автоматический fallback на `gemini-1.5-pro` если flash недоступна
- Fallback на старую модель `gemini-pro` для совместимости

### 3. Улучшенная обработка ошибок
- Более информативные сообщения об ошибках
- Обработка ошибок квоты API
- Обработка ошибок неверного API ключа
- Логирование выбранной модели при инициализации

### 4. Обновление зависимостей
- Обновлена версия `google-generativeai` до >=0.8.0 для поддержки новых моделей

### 5. Улучшенный формат сообщений
- Корректное преобразование формата сообщений из OpenAI в Gemini формат
- Правильная обработка ролей (user/assistant -> user/model)

## Использование

### Настройка API ключа

Добавьте в переменные окружения:
```bash
GEMINI_API_KEY=your-api-key-here
```

Получить API ключ можно здесь: https://makersuite.google.com/app/apikey

### Проверка работы

После настройки API ключа, Gemini будет автоматически доступен в списке провайдеров.

Модель выбирается автоматически в следующем порядке:
1. `gemini-1.5-flash` (предпочтительно)
2. `gemini-1.5-pro` (если flash недоступна)
3. `gemini-pro` (legacy fallback)

## Особенности

- **История разговора**: Gemini теперь правильно использует историю сообщений через ChatSession
- **Стриминг**: Поддержка потоковой передачи ответов
- **Обработка ошибок**: Улучшенные сообщения об ошибках для пользователя

## Технические детали

### Формат истории сообщений

Gemini API использует формат:
```python
[
    {'role': 'user', 'parts': ['сообщение пользователя']},
    {'role': 'model', 'parts': ['ответ модели']},
    ...
]
```

Класс `GeminiProvider` автоматически конвертирует формат OpenAI (`user`/`assistant`) в формат Gemini (`user`/`model`).

### ChatSession

Для работы с историей используется `model.start_chat(history=...)`, который создает сессию с контекстом предыдущих сообщений.
